{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKKTX2NeYPjc"
   },
   "source": [
    "# Implementarea unei Retele Neurale cu un singur strat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqRC3npbZGHw"
   },
   "source": [
    "In acest exercitiu o sa creati o retea neurala cu un singur strat. Stratul ascuns este conectat la tot inputul si este folosit pentru a clasifica si a testa imagini din datasetul CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1518642040190,
     "user": {
      "displayName": "Ioana Veronica Chelu",
      "photoUrl": "//lh3.googleusercontent.com/-cgSbSmZley0/AAAAAAAAAAI/AAAAAAAAAkQ/tlyfATNBo0o/s50-c-k-no/photo.jpg",
      "userId": "105713609374122750645"
     },
     "user_tz": -120
    },
    "id": "KtCFA_axXuSP",
    "outputId": "f89abbe1-ea3b-476b-d259-43000edb3abb"
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import mnist\n",
    "# initializare pentru matplotlib\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # setarea dimensiunii plot-urilor \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# auto-reloading pentru module externe\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" intoarce eroarea relativa \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_ogHHgy1Wq8"
   },
   "source": [
    "# Definirea retelei\n",
    "\n",
    "Vom defini reteaua cu un singur layer ascuns cu o clasa. Reteaua primeste ca input x de dimensiunea \"input_dim\", are un strat ascuns de dimensiune \"hidden_dim\". Aceasta clasifica input-ul in una din cele \"num_classes\". \n",
    "La iesire, reteaua trece score-urile calculate pe ultimul strat fully_connected printr-o functie **softmax** pentru a scoate probabilitati. \n",
    "\n",
    "Functia obiectiv este **cross-entropia**. Adaugam ca regularizare **L2_norm** pe matricile parametrilor (fara bias). Reteaua are o functie non-liniara dupa primul strat fully_connected. Vom folosi **ReLU** pentru aceasta nonliniaritate.\n",
    "\n",
    "Reteaua are urmatoarea arhitectura: input - fully_connected - ReLU - fully_connected - softmax.\n",
    "Output-ul celui de-al doilea strat de fully_connected reprezinta score-urile claselor.\n",
    "\n",
    "Scheletul de cod pentru **ShallowNet** de afla in fisierul **shallow_net.py** pentru a putea lucra in paralel la cele doua fisiere. Alte functii ajutatoare pe care le veti intalni pe parcurs se afla in **utils.py**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gE1FLhMn_mvN"
   },
   "source": [
    "# Data de intrare de test\n",
    "Vom crea o retea simpla cu un singur strat ascuns si vom folosi niste date random pentru a testa corectitudinea implementarii unei propagari inainte si inapoi prin retea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dQCAZ-bDAOoa"
   },
   "outputs": [],
   "source": [
    "from shallow_net import ShallowNet\n",
    "input_dim = 4\n",
    "hidden_dim = 10\n",
    "num_classes = 3\n",
    "dataset_size = 5\n",
    "\n",
    "np.random.seed(0)\n",
    "net = ShallowNet(input_dim, hidden_dim, num_classes, std=1e-1)\n",
    "\n",
    "np.random.seed(1)\n",
    "X_train = 10 * np.random.randn(dataset_size, input_dim)\n",
    "y_train = np.array([0, 1, 2, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yu3ho1zB7q3"
   },
   "source": [
    "# Propagare inainte (Forward pass)\n",
    "## Calcularea scorurilor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1518624320580,
     "user": {
      "displayName": "Ioana Veronica Chelu",
      "photoUrl": "//lh3.googleusercontent.com/-cgSbSmZley0/AAAAAAAAAAI/AAAAAAAAAkQ/tlyfATNBo0o/s50-c-k-no/photo.jpg",
      "userId": "105713609374122750645"
     },
     "user_tz": -120
    },
    "id": "heifQCr_CTCg",
    "outputId": "8e776228-d69c-479e-8de7-9afea1d80093"
   },
   "outputs": [],
   "source": [
    "scores = net.loss(X_train)\n",
    "print(scores)\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "# Differenta ar trebui sa fie foarte mica < 1e-7\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYpWbCtx5yYL"
   },
   "source": [
    "## Calcularea erorii\n",
    "In aceeasi functie trebuie sa definim partea a doua in care calculam eroare pentru setul de date de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1518624321376,
     "user": {
      "displayName": "Ioana Veronica Chelu",
      "photoUrl": "//lh3.googleusercontent.com/-cgSbSmZley0/AAAAAAAAAAI/AAAAAAAAAkQ/tlyfATNBo0o/s50-c-k-no/photo.jpg",
      "userId": "105713609374122750645"
     },
     "user_tz": -120
    },
    "id": "EuFgbfOB6J41",
    "outputId": "60411f1b-b0e8-47a2-a84c-93f667e0f5b1"
   },
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X_train, y_train, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# diferenta ar trebui sa fie foarte mica < 1e-12\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagare inapoi (Backpropagation)\n",
    "Implementare completa a functiei loss pentru a cumprinde si gradientul functiei de cost pentru variabilele fc1_w, fc1_b, fc2_w, fc2_b.\n",
    "Pentru a testa corectitudienea implementarii gradientului putem folosi graientul numeric: (f(x-h) - f(x+h)) / 2h , h -> 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import eval_numerical_gradient\n",
    "\n",
    "loss, grads = net.loss(X_train, y_train, reg=0.05)\n",
    "# diferenta ar trebui sa fie foarte mica < 1-8\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X_train, y_train, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antrenarea retelei (training)\n",
    "Vom antrena reteaua folosin stochastic gradient descent(SGD). \n",
    "In acest pas vom completa functia **train** din clasa ShallowNet. Vom completa de asemenea si functia **predict** pentru a afisa acuratetea retelei in timpul antrenarii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = net.train(X_train, y_train, X_train, y_train, \n",
    "                  learning_rate=1e-1, reg=5e-6,\n",
    "                  num_iters=100, verbose=False)\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# plotarea costului\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPt6-ZetZkyB"
   },
   "source": [
    "# Incarcarea datasetului - CIFAR-10\n",
    "Vom incarca datasetul folosindu-ne de **keras**. \n",
    "\n",
    "**Keras** este un wrapper peste **tensorflow** **(framework de deep learning)**. In laboaratoarele viitoare veti folosi tensorflow pentru a scrie retele. Tensorflow are scrise deja biblioteci de functii in C++ ce folosesc rutine optimizate pentru a rula cod cuda pe GPU. Pe acestea le veti apela direct din python. \n",
    "\n",
    "In laboratorul de astazi incercam sa implementam totul de mana direct in python pentru a intelege \"magic\"-ul din spatele Tensorflow-ului."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_1xpZMja_e1"
   },
   "source": [
    "**CIFAR-10** este un dataset ce contine 50000 de imagini de train si 10000 imagini de test. Acestea eu dimensiuni 32x32x3. O sa spargem imaginile de train in doua splituri pentru a pastra 10000 de imagini pentru validare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "y7BwnpjfXwAW"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_val = X_train[40000:]\n",
    "X_train = X_train[:40000]\n",
    "y_val = y_train[40000:]\n",
    "y_train = y_train[:40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ut9nJJBaafcX"
   },
   "source": [
    "Imaginile vor fi **vectorizate** inainte de a fi trimise retelei.\n",
    "\n",
    "**Numarul de clase din CIFAR-10** este (big surprise here!) 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTCHuWmCv4aZ"
   },
   "source": [
    "### Preprocesarea datasetului\n",
    "La acest pas, trebuie sa faceti o preprocesare minimala, normalizarea fiecarei imagini scazand valoarea medie peste tot datasetul. Imaginile sunt matrixi 32x32x3 cu tipul uint8, iar noi avem nevoie vectori de tip float32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LYeFH74Qa9FH"
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    X_train = X_train.reshape(y_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(y_test.shape[0], -1)\n",
    "    X_val = X_val.reshape(y_val.shape[0], -1)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_val = X_val.astype('float32')\n",
    "    y_train = y_train.reshape(y_train.shape[0])\n",
    "    y_test = y_test.reshape(y_test.shape[0])\n",
    "    y_val = y_val.reshape(y_val.shape[0])\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_val -= mean_image\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Rmp6O9ZhY7Kj"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_dataset(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Val data shape: ', X_val.shape)\n",
    "print('Val labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6829NYnCw4Mc"
   },
   "source": [
    "## Antrenarea retelei pe CIFAR-10\n",
    "Pentru a antrena reteaua folosim SGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_C1VVbfBxiYC"
   },
   "outputs": [],
   "source": [
    "input_size = 32\n",
    "input_channels = 3\n",
    "input_dim = input_channels * input_size * input_size\n",
    "hidden_dim = 50\n",
    "num_classes = 10\n",
    "net = ShallowNet(input_dim, hidden_dim, num_classes)\n",
    "# Antrenam reteaua\n",
    "stats = net.train(np.concatenate([X_train, X_test], 0), np.concatenate([y_train, y_test], 0), X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "# Facem preziceri pe datasetul de test si calculam acuratetea\n",
    "test_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Test accuracy: ', test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug procesul de antrenare\n",
    "Test accuracy ar trebui sa fie cu parametrii de mai sus undeva la 0.28. Aceasta este o acuratete foarte mica, random ar fi undeva la 0.10, deci nu suntem foarte departe.\n",
    "Pentru a vedea ce sa intampla cu antrenarea putem plota valorile erorii pentru antrenare si test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import visualize_grid\n",
    "\n",
    "# Vizualizarea parametrilor retelei\n",
    "\n",
    "def show_net_weights(net, param_key):\n",
    "    W1 = net.params[param_key]\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net, 'fc1_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunarea hiperparametrilor\n",
    "Cateva observatii:\n",
    "* costul scade liniar ceea ce ar putea sugera ca putem mari rata de invatare\n",
    "* nu exista niciun gap intre plotul accuratetii pe datale de invatare vs datele de test ceea ce ar putea sugera ca suntem in regimul de 'underfitting' si avem un model cu capacitate prea mica.\n",
    "* pentru a dezvolta o intuitie de ce hiperparametrii merg in ce situatii, trebuie experimentat mult. Puteti experimenta cu diferite valori pentru urmatorii hiperparametrii: numarul de neuroni pe stratul ascuns (hidden_dim), rata de invatare etc. \n",
    "* in principiu ne dorim o acuratete pe datale de test > 48%.\n",
    "* pentru a ajunge la o acuratete foarte mare, sunt foarte multe trick-uri pe care le vom invata in episoadele urmatoare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = net # cel mai bun model\n",
    "\n",
    "#################################################################################\n",
    "# TODO: Tunarea hiperparametrilor pe datele de validare.                        #\n",
    "# Cel mai bun model trebuie stocat in best_net.                                 #\n",
    "# Hint: Cea mai simpla tunare poate fi o iterare prin mai multe valori ale      #                            #\n",
    "# parametrilor pentru hidden_dim, learning_rate, l2_reg, etc.  Departajarea     #\n",
    "# celui mai bun model se poate face dupa acuratete                              #\n",
    "#################################################################################\n",
    "pass\n",
    "#################################################################################\n",
    "#                               END OF YOUR CODE                                #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the weights of the best network\n",
    "show_net_weights(best_net, 'fc1_w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rularea pe datele de test \n",
    "Testul final al unei retele este rularea acesteia pe datele de test. De obiecei acestea sunt niste date pastrate deoparte pentru care nu avem label-urile/etichetele. De exemplu, in cadrul unei competitii, se vor publica datele de antrenare cu label-urile corespunzatoare acestora pentru antrenarea unui model, datele de validare cu label-urile corespunzatoare acestora pentru tunarea hiperparametrilor dupa antrenare, si datele de testare fara label-uri. Submisia in cardul unei competitii este facuta cu prezicerile modelului pentru datele de test.\n",
    "\n",
    "In cazul de fata, noi vom fi si evaluatori, avand deja etichetele reale, putem sa ne calculam singuri acuratetea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "solver.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
